{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [],
    "trusted": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import math\n",
    "from filelock import FileLock\n",
    "import random\n",
    "\n",
    "# __import_lightning_begin__\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "# __import_lightning_end__\n",
    "\n",
    "# __import_tune_begin__\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter, JupyterNotebookReporter\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback\n",
    "# __import_tune_end__\n",
    "\n",
    "from FashionMNISTLightningDataModule import FashionMNISTLightningDataModule\n",
    "from augmentation.augmentation import TRANSFORM_NAMES\n",
    "from FashionMNISTLightningModule import FashionMNISTLightningModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "log = logging.getLogger('App')\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "def train_mnist_tune_checkpoint(config,\n",
    "                                checkpoint_dir=None,\n",
    "                                # no really used, we stop after every epoch and let tune decide what to do\n",
    "                                num_epochs=999,\n",
    "                                num_gpus=0):\n",
    "    # data_dir = os.path.expanduser(\"~/data\")\n",
    "    data_dir = config[\"data_dir\"]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=num_epochs,\n",
    "        # If fractional GPUs passed in, convert to int.\n",
    "        gpus=math.ceil(num_gpus),\n",
    "        logger=TensorBoardLogger(save_dir=tune.get_trial_dir(), name=\"\", version=\".\"),\n",
    "        progress_bar_refresh_rate=config[\"progress_bar_refresh_rate\"],\n",
    "        num_sanity_val_steps=0,\n",
    "        callbacks=[\n",
    "            TuneReportCheckpointCallback(\n",
    "                metrics={\n",
    "                    \"loss\": \"ptl/val_loss\",\n",
    "                    \"mean_accuracy\": \"ptl/val_acc\"\n",
    "                },\n",
    "                filename=\"checkpoint\",\n",
    "                on=\"validation_end\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model = FashionMNISTLightningModule.load_from_checkpoint(os.path.join(checkpoint_dir, \"checkpoint\"), conf=config)\n",
    "        log.info('Lightning loaded from checkpoint')\n",
    "    else:\n",
    "        model = FashionMNISTLightningModule(conf=config)\n",
    "        log.info('Lightning initialized')\n",
    "\n",
    "    data = FashionMNISTLightningDataModule(conf=config)\n",
    "\n",
    "    trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "def tune_mnist_pbt(num_samples=15, training_iteration=15, gpus_per_trial=0):\n",
    "    def explore(config):\n",
    "        log.info(\"======================================= EXPLORE =========================================\")\n",
    "        # calculate new magnitudes for augmentations\n",
    "        augmentations = []\n",
    "        for tfn_name in TRANSFORM_NAMES:\n",
    "            augmentations.append((tfn_name, random.random()))\n",
    "\n",
    "        config[\"augmentations\"] = augmentations\n",
    "        log.info(config)\n",
    "        return config\n",
    "\n",
    "    scheduler = PopulationBasedTraining(\n",
    "        time_attr=\"training_iteration\",\n",
    "        # Models will be considered for perturbation at this interval of time_attr=\"time_total_s\"\n",
    "        perturbation_interval=1,\n",
    "        custom_explore_fn=explore,\n",
    "        log_config=True\n",
    "    )\n",
    "\n",
    "    reporter_jupyter = JupyterNotebookReporter(\n",
    "        overwrite=True,\n",
    "        parameter_columns=[\"augmentations\"],\n",
    "        metric_columns=[\"loss\", \"mean_accuracy\", \"training_iteration\"]\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    # initial config\n",
    "            config={\n",
    "            \"progress_bar_refresh_rate\": 0,\n",
    "            \"layer_1_size\": tune.choice([32, 64, 128, 256, 512, 1024]),\n",
    "            \"layer_2_size\": tune.choice([32, 64, 128, 256, 512, 1024]),\n",
    "            \"lr\": tune.choice([1e-2, 1e-3, 1e-4, 1e-5, 1e-6]),\n",
    "            \"batch_size\": tune.choice([32, 64, 128, 256, 512, 1024, 2048]),\n",
    "        },\n",
    "    \"\"\"\n",
    "\n",
    "    # set up the augmentations\n",
    "    # tuple of augmentation name and its magnitude\n",
    "    augmentations = []\n",
    "    for tfn_name in TRANSFORM_NAMES:\n",
    "        augmentations.append((tfn_name, random.random()))\n",
    "\n",
    "    config={\n",
    "        # https://docs.ray.io/en/master/tune/api_docs/search_space.html?highlight=tune.choice#\n",
    "        \"progress_bar_refresh_rate\": 0,\n",
    "        \"layer_1_size\": 512,\n",
    "        \"layer_2_size\": 512,\n",
    "        \"lr\": 0.00005 ,\n",
    "        \"batch_size\": 1024,\n",
    "        \"data_dir\": \"./data\",\n",
    "        \"data_mean\": 0.28604063391685486,\n",
    "        \"data_std\": 0.35302430391311646,\n",
    "        \"augmentations\": augmentations,\n",
    "    }\n",
    "\n",
    "    analysis = tune.run(\n",
    "        tune.with_parameters(\n",
    "            train_mnist_tune_checkpoint,\n",
    "            num_gpus=gpus_per_trial),\n",
    "        resources_per_trial={\n",
    "            \"cpu\": 1 / 16,\n",
    "            \"gpu\": gpus_per_trial\n",
    "        },\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter_jupyter,\n",
    "        verbose=1,\n",
    "        name=\"FashionMNIST-pbt\",\n",
    "        stop={  # Stop a single trial if one of the conditions are met\n",
    "            \"mean_accuracy\": 0.95,\n",
    "            \"training_iteration\": training_iteration},\n",
    "        local_dir=\"./data\",\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found were: \", analysis.best_config)\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2021-12-11 23:30:46 (running for 00:02:00.99)<br>Memory usage on this node: 34.1/64.0 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 0/10 CPUs, 0/0 GPUs, 0.0/19.81 GiB heap, 0.0/9.91 GiB objects<br>Result logdir: /Users/akaver/Dev/PhD/pbt-demo-mnist/data/FashionMNIST-pbt<br>Number of trials: 16/30 (16 PENDING)<br><table>\n<thead>\n<tr><th>Trial name                             </th><th>status  </th><th>loc  </th><th>augmentations                                                                                               </th></tr>\n</thead>\n<tbody>\n<tr><td>train_mnist_tune_checkpoint_525f7_00000</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00001</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00002</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00003</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00004</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00005</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00006</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00007</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00008</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00009</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00010</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00011</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00012</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00013</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00014</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n<tr><td>train_mnist_tune_checkpoint_525f7_00015</td><td>PENDING </td><td>     </td><td>[(&#x27;blur&#x27;, 0.8293034766867767), (&#x27;rotate_left&#x27;, 0.023870989116744457), (&#x27;rotate_right&#x27;, 0.10642285066768153)]</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 23:30:47,088\tERROR tune.py:626 -- Trials did not complete: [train_mnist_tune_checkpoint_525f7_00000, train_mnist_tune_checkpoint_525f7_00001, train_mnist_tune_checkpoint_525f7_00002, train_mnist_tune_checkpoint_525f7_00003, train_mnist_tune_checkpoint_525f7_00004, train_mnist_tune_checkpoint_525f7_00005, train_mnist_tune_checkpoint_525f7_00006, train_mnist_tune_checkpoint_525f7_00007, train_mnist_tune_checkpoint_525f7_00008, train_mnist_tune_checkpoint_525f7_00009, train_mnist_tune_checkpoint_525f7_00010, train_mnist_tune_checkpoint_525f7_00011, train_mnist_tune_checkpoint_525f7_00012, train_mnist_tune_checkpoint_525f7_00013, train_mnist_tune_checkpoint_525f7_00014, train_mnist_tune_checkpoint_525f7_00015]\n",
      "2021-12-11 23:30:47,089\tINFO tune.py:630 -- Total run time: 121.24 seconds (120.99 seconds for the tuning loop).\n",
      "2021-12-11 23:30:47,089\tWARNING tune.py:634 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n",
      "2021-12-11 23:30:47,091\tWARNING experiment_analysis.py:677 -- Could not find best trial. Did you pass the correct `metric` parameter?\n",
      "2021-12-11 23:30:47,092\tWARNING experiment_analysis.py:677 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  None\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'525f7_00000': {'trial_id': '525f7_00000'},\n '525f7_00001': {'trial_id': '525f7_00001'},\n '525f7_00002': {'trial_id': '525f7_00002'},\n '525f7_00003': {'trial_id': '525f7_00003'},\n '525f7_00004': {'trial_id': '525f7_00004'},\n '525f7_00005': {'trial_id': '525f7_00005'},\n '525f7_00006': {'trial_id': '525f7_00006'},\n '525f7_00007': {'trial_id': '525f7_00007'},\n '525f7_00008': {'trial_id': '525f7_00008'},\n '525f7_00009': {'trial_id': '525f7_00009'},\n '525f7_00010': {'trial_id': '525f7_00010'},\n '525f7_00011': {'trial_id': '525f7_00011'},\n '525f7_00012': {'trial_id': '525f7_00012'},\n '525f7_00013': {'trial_id': '525f7_00013'},\n '525f7_00014': {'trial_id': '525f7_00014'},\n '525f7_00015': {'trial_id': '525f7_00015'}}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis = tune_mnist_pbt(num_samples=30, training_iteration=15, gpus_per_trial=1/8)\n",
    "analysis.best_config\n",
    "analysis.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/html": "== Status ==<br>Memory usage on this node: 40.4/62.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/35.32 GiB heap, 0.0/17.66 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST<br>Number of trials: 16/16 (16 ERROR)<br>Number of errored trials: 16<br><table>\n<thead>\n<tr><th>Trial name                             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                             </th></tr>\n</thead>\n<tbody>\n<tr><td>train_mnist_tune_checkpoint_575ec_00000</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00000_0_batch_size=256,layer_1_size=1024,layer_2_size=128,lr=0.0001_2021-09-28_01-29-13/error.txt </td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00001</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00001_1_batch_size=256,layer_1_size=512,layer_2_size=512,lr=1e-05_2021-09-28_01-29-13/error.txt   </td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00002</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00002_2_batch_size=32,layer_1_size=512,layer_2_size=64,lr=0.01_2021-09-28_01-29-13/error.txt      </td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00003</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00003_3_batch_size=64,layer_1_size=512,layer_2_size=1024,lr=1e-05_2021-09-28_01-29-13/error.txt   </td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00004</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00004_4_batch_size=1024,layer_1_size=1024,layer_2_size=64,lr=0.01_2021-09-28_01-29-14/error.txt   </td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00005</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00005_5_batch_size=32,layer_1_size=1024,layer_2_size=64,lr=0.0001_2021-09-28_01-29-14/error.txt   </td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00006</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00006_6_batch_size=512,layer_1_size=64,layer_2_size=1024,lr=0.01_2021-09-28_01-29-14/error.txt    </td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00007</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00007_7_batch_size=256,layer_1_size=1024,layer_2_size=64,lr=0.0001_2021-09-28_01-29-14/error.txt  </td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00008</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00008_8_batch_size=512,layer_1_size=512,layer_2_size=256,lr=1e-06_2021-09-28_01-29-14/error.txt   </td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00009</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00009_9_batch_size=2048,layer_1_size=32,layer_2_size=128,lr=1e-06_2021-09-28_01-29-14/error.txt   </td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00010</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00010_10_batch_size=2048,layer_1_size=32,layer_2_size=256,lr=0.01_2021-09-28_01-29-14/error.txt   </td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00011</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00011_11_batch_size=32,layer_1_size=1024,layer_2_size=32,lr=1e-06_2021-09-28_01-29-15/error.txt   </td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00012</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00012_12_batch_size=128,layer_1_size=512,layer_2_size=64,lr=0.01_2021-09-28_01-29-15/error.txt    </td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00013</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00013_13_batch_size=2048,layer_1_size=64,layer_2_size=256,lr=1e-05_2021-09-28_01-29-15/error.txt  </td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00014</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00014_14_batch_size=2048,layer_1_size=1024,layer_2_size=128,lr=1e-05_2021-09-28_01-29-15/error.txt</td></tr>\n<tr><td>train_mnist_tune_checkpoint_575ec_00015</td><td style=\"text-align: right;\">           1</td><td>/home/akaver/!Dev/pbt-demo-mnist/data/FashionMNIST/train_mnist_tune_checkpoint_575ec_00015_15_batch_size=32,layer_1_size=64,layer_2_size=1024,lr=1e-05_2021-09-28_01-29-15/error.txt   </td></tr>\n</tbody>\n</table><br>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_mnist_tune_checkpoint_575ec_00000, train_mnist_tune_checkpoint_575ec_00001, train_mnist_tune_checkpoint_575ec_00002, train_mnist_tune_checkpoint_575ec_00003, train_mnist_tune_checkpoint_575ec_00004, train_mnist_tune_checkpoint_575ec_00005, train_mnist_tune_checkpoint_575ec_00006, train_mnist_tune_checkpoint_575ec_00007, train_mnist_tune_checkpoint_575ec_00008, train_mnist_tune_checkpoint_575ec_00009, train_mnist_tune_checkpoint_575ec_00010, train_mnist_tune_checkpoint_575ec_00011, train_mnist_tune_checkpoint_575ec_00012, train_mnist_tune_checkpoint_575ec_00013, train_mnist_tune_checkpoint_575ec_00014, train_mnist_tune_checkpoint_575ec_00015])",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTuneError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_172577/909255142.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0mstart_time\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     \u001B[0manalysis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtune_mnist_pbt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_samples\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m16\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgpus_per_trial\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mexperiments_to_run_in_parallel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0melapsed_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mstart_time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_172577/665182895.py\u001B[0m in \u001B[0;36mtune_mnist_pbt\u001B[0;34m(num_samples, num_epochs, gpus_per_trial)\u001B[0m\n\u001B[1;32m     57\u001B[0m     )\n\u001B[1;32m     58\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m     analysis = tune.run(\n\u001B[0m\u001B[1;32m     60\u001B[0m         tune.with_parameters(\n\u001B[1;32m     61\u001B[0m             \u001B[0mtrain_mnist_tune_checkpoint\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/ray/tune/tune.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)\u001B[0m\n\u001B[1;32m    542\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mincomplete_trials\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    543\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mraise_on_failed_trial\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msignal\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSIGINT\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 544\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mTuneError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Trials did not complete\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mincomplete_trials\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    545\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    546\u001B[0m             \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merror\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Trials did not complete: %s\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mincomplete_trials\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTuneError\u001B[0m: ('Trials did not complete', [train_mnist_tune_checkpoint_575ec_00000, train_mnist_tune_checkpoint_575ec_00001, train_mnist_tune_checkpoint_575ec_00002, train_mnist_tune_checkpoint_575ec_00003, train_mnist_tune_checkpoint_575ec_00004, train_mnist_tune_checkpoint_575ec_00005, train_mnist_tune_checkpoint_575ec_00006, train_mnist_tune_checkpoint_575ec_00007, train_mnist_tune_checkpoint_575ec_00008, train_mnist_tune_checkpoint_575ec_00009, train_mnist_tune_checkpoint_575ec_00010, train_mnist_tune_checkpoint_575ec_00011, train_mnist_tune_checkpoint_575ec_00012, train_mnist_tune_checkpoint_575ec_00013, train_mnist_tune_checkpoint_575ec_00014, train_mnist_tune_checkpoint_575ec_00015])"
     ]
    }
   ],
   "source": "from time import sleep, perf_counter as pc\n\nresults = []\nfor models in range(8):\n    experiments_to_run_in_parallel = (models + 1) * 2\n    print(f\"Starting {experiments_to_run_in_parallel} experiments in parallel\")\n    start_time = pc()\n\n    analysis = tune_mnist_pbt(num_samples=16, num_epochs=5, gpus_per_trial=1 / experiments_to_run_in_parallel)\n\n    elapsed_time = pc() - start_time\n    results.append((models, elapsed_time))\n\nresults"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[(0, 1250.4137557320064),\n (1, 1054.7564893119998),\n (2, 978.0088943799929),\n (3, 1215.7183314590075),\n (4, 1026.1449859720015),\n (5, 1067.1325380739872),\n (6, 1058.9811587199947)]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "results"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}